# PCANet在不同数据库上进行测试

## FERET 

FERET数据库包含1196个人，在不同光照、三年时间、各种表情的设置下，每个人包含5张图片。整个数据集划分为互不相交的两个集合：训练集(Fa)和测试集，测试集进一步划分为4个子集：Fb代表不同表情的变化，Fc代表光照的变化，Dup-I代表在3到4个月内拍摄的图片，Dup-II代表至少在一年半内拍摄的图片。

### 实验设置

使用灰度图片，裁剪到150*90的尺寸。PCANet网络结构参数设置：层数为2，卷积核大小为5\*5，每层卷积核个数为8，直方图子区域大小为15\*15，并且直方图子区域之间没有重叠。卷积核采用之前在MultiPIE数据集上学习得到的卷积核，利用Whitening PCA(WPCA)的方式，在训练集学习得到投影矩阵，降维到1000维。距离计算采用cosine距离，利用最近邻匹配来做人脸识别。

### 实验结果

训练集采用Fa，在测试集Dup-II上作测试，结果94.02%，论文中为94.02%。

## MNIST

在手写数字数据集上进行测试。总共具有9个分类任务，所有图片的尺寸为28*28的灰度图片。在我们的实验中，选择MNIST Basic这一分类任务做测试。

### 实验设置

PCANet网络结构参数设置：层数为2，卷积核大小为7\*7，每层卷积核个数为8，直方图子区域大小为7\*7，并且直方图子区域之间重叠的比重占子区域的50%。在训练集上训练得到卷积核并得到训练集的PCANet特征，训练linear SVM；利用之前得到的卷积核在测试集上提取测试数据的PCANet特征，利用linear SVM做测试。

### 实验结果

在测试集上的测试结果错误率(1-Accuracy)为1.07%，论文：1.06%。

## LFW

关于这部分数据集的介绍可参考[LFW协议使用指南](http://10.214.164.248/summary/chenjingzhou/blob/master/总结-10-30-11-3.md)。在进行测试时，我们从原始版本的数据集开始，逐步换用不同的数据集，调整参数，以达到确认每步在结果中所起的作用。

### 实验设置

LFW数据集中，View1数据集是用来调整提高模型的，因此我们在这一部分数据集上调参。因为在PCANet论文中已经对卷积核个数对结果的影响作以探究了，结果表明8个以上卷积核效果就已经很好了，因此我们在以后的实验中都将两层卷积核的个数都固化为8个，从而探究卷积核大小和直方图子区域大小在PCANet分类问题中的影响。另一方面，限于PCANet网络本身的限制，我们将层数限制为两层。各个直方图子区域之间不重叠，先不引入过采样的影响。

#### LFW-Original

原始数据集图片为250*250的灰度图片，图片中包含了至少一张人脸，而且背景变化较复杂。我们从这一最原始的数据集开始。

##### 卷积核大小对分类结果的影响

PCANet网络结构参数：每层卷积核个数8个，网络层数两层，直方图子区域大小15*13。降维维数为3200维。在View1数据集的训练集上训练得到卷积核和降维矩阵，在测试集上利用得到卷积核和降维矩阵获取PCANet特征，在测试集上获取Face Verification的最佳阈值，并返回测试集上Verification的结果。

| 卷积核尺寸       | 5*5   | 7\*7  | 15\*15 |
| ----------- | ----- | ----- | ------ |
| Accuracy(%) | 67.10 | 68.80 | 67.40  |

卷积核大小对结果并没有产生很大的影响。

##### 直方图子区域大小对分类结果的影响

PCANet网络结构参数：每层卷积核个数8个，网络层数两层，卷积核大小为7*7。降维维数为3200维。在View1数据集的训练集上训练得到卷积核和降维矩阵，在测试集上利用得到卷积核和降维矩阵获取PCANet特征，在测试集上获取Face Verification的最佳阈值，并返回测试集上Verification的结果。

| 直方图子区域大小    | 15*13 | 25\*25 | 50\*50 |
| ----------- | ----- | ------ | ------ |
| Accuracy(%) | 68.80 | 70.20  | 69.30  |

增大直方图子区域对结果的确有一定的提升，一种合理的解释是扩大直方图子区域可以利用这一更大区域的统计特征对诸如平移、旋转之类的问题具有更大的鲁棒性，PCANet论文中的实验也有提及这一点。但是子区域尺寸并不是越大越好，这或许会造成丢失一些局部细节特征。

##### 降维维数对结果的影响

因为View1数据集训练集总共有2200对图片，共4400张图片，因此做降维时最多有4400维。PCANet网络结构参数：每层卷积核个数8个，网络层数两层，卷积核大小为7*7，直方图子区域大小为15\*13。在View1数据集的训练集上训练得到卷积核和降维矩阵，在测试集上利用得到卷积核和降维矩阵获取PCANet特征，在测试集上获取Face Verification的最佳阈值，并返回测试集上Verification的结果。

| 降维维数        | 1000 | 3200  |
| ----------- | ---- | ----- |
| Accuracy(%) | 67.5 | 68.80 |

降维维数对结果的影响不大。

##### View1的训练集上获取Verification的阈值

之前我们的实验在View1的训练集上训练得到卷积核和降维矩阵，在测试集上得到Verification的最佳阈值。如果我们全部只在View1的训练集上进行呢？PCANet网络结构参数：每层卷积核个数8个，网络层数两层，卷积核大小为7*7，直方图子区域大小为15\*13，降维维数为3200。

| 阈值获取，Verification结果获得 | 训练集获取阈值，训练集测试 | 训练集获取阈值，测试集测试 |
| --------------------- | ------------- | ------------- |
| Accuracy(%)           | 63.05         | 68.80         |

可以看到结果相差较大，进一步去探究这个过程。在训练集上训练并获取阈值，得到训练集中各个图片对的距离，求其均值为0.99，方差为0.01；在训练集上训练并在测试集上获取阈值，得到测试集中各个图片对的距离，求其均值为0.98，方差为0.08。这样的结果反映出在训练集上训练并提取PCANet特征后，再在训练集上计算阈值，不同图片对与相同图片对间的差异，相较于测试集上获取阈值来说小了很多。我们能否假设PCANet在训练集上抽象并提取出了共有特征，并导致训练集上人脸的类间差异很小呢？

#### LFW-Aligned

在人脸识别中，人脸矫正这一步对结果有着比较大的影响，因此我们在原始数据集上，进一步采用经过人脸矫正后的版本lfw-a(经过商业系统矫正的版本)。实验设置上，我们采用之前在原始数据集上得到最好结果的一套参数进行测试。即PCANet网络结构参数：每层卷积核个数8个，网络层数两层，卷积核大小为7*7，直方图子区域大小为25\*25。在View1数据集的训练集上训练得到卷积核和降维矩阵，在测试集上利用得到卷积核和降维矩阵获取PCANet特征，在测试集上获取Face Verification的最佳阈值，并返回测试集上Verification的结果。

| 数据库         | LFW-Original | LFW-Aligned |
| ----------- | ------------ | ----------- |
| Accuracy(%) | 70.2         | 72          |

结果有小幅提升。

#### LFW-Aligned-Cropped

在之前的测试中，每张图片中除了包含待识别的人脸，甚至可能还包含其他人的人脸，背景变化也比较复杂，因此在这里我们利用Viola-Jones算法先进行人脸检测，然后在检测到人脸框中，从中心点开始截取150*80的区域作为人脸，以最大限度地剔除背景的影响。PCANet网络结构的参数设置上，网络层数设置为两层，卷积核大小为7\*7，每层卷积核个数为8个。因为在PCANet论文中直方图子区域大小设置为15\*13，我们这里采用两种设置，论文中的设置和之前25\*25的设置。

| 直方图子区域      | 15*13 | 25\*25 |
| ----------- | ----- | ------ |
| Accuracy(%) | 82.70 | 82.10  |

同样地，我们也在阈值的获取上进行之前一样的对比，直方图子区域大小设置为15*13，其他设置同上。

| 阈值获取，Verification结果获得 | 训练集获取阈值，训练集测试 | 训练集获取阈值，测试集测试 |
| --------------------- | ------------- | ------------- |
| Accuracy(%)           | 67.82         | 82.70         |

在View1上获得阈值之后，在View2上进行测试。PCANet网络结构参数设定为：网络层数设置为两层，卷积核大小为7\*7，每层卷积核个数为8个，直方图子区域大小设置为15\*13。这里我们也进行两种方式测试，第一种是利用View1训练集上得到卷积核和降维矩阵，View1测试集上获取的阈值，在View2上直接做测试；第二种利用十折交叉验证的方式，每一折在View2的训练集上获取卷积核和降维矩阵，利用View1测试集上获取的阈值，在View2测试集上进行测试。

| 测试方式        | 第一种   | 第二种   |
| ----------- | ----- | ----- |
| Accuracy(%) | 76.07 | 83.23 |

## 问题探究

1. PCANet特征提取的方式决定了它的网络结构不能做的很深，如果加以改进做得更深呢？
2. 特征提取的过程即是特征设计的过程，CNN可以说设计出了很好的特征，并且对许多问题具有较高的鲁棒性，但是这一特征并不为我们所知；反观PCANet，依据我们先验的知识进行特征设计，包括子区域块的划分，多层PCA的方式生成卷积核，二值化的方式压缩图像，子区域的划分进行直方图特征的提取，我们或许可以对其中个别的一些操作有一些常识性的洞见，但终究还是要回到一个问题：这样的特征设计是否针对我的问题足够有效，即它真的提取出了对问题很关键的信息了吗？最后，或许在不同数据集的一些测试上，PCANet得到了不错的效果，但是在一些测试中(诸如LFW中利用View1计算得到卷积核和降维矩阵直接在View2做测试的效果不如在View2上采用十折交叉验证的方式)，以及实际测试中(希望我尽可能地避免了自己的问题，而归结到了算法的问题)的效果并不尽如人意，或许我们可以说，PCANet的效果还会因数据集而异，相对地，不如神经网络泛化效果好。那么我们是否可以说，在人脸识别问题上，PCANet这种特征提取方式，除了提取有关人脸地特征，还受到一些其他问题影响提取特征的过程？那么神经网络呢？或许，还需要进一步深入对比这两种方式，才能有更多的一些线索吧。